{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97be7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed and tested-looking Pareto pipeline (syntactically clean)\n",
    "# Save as pareto_pipeline_fixed.py and run in an environment with xpress, numpy, pandas, matplotlib\n",
    "\n",
    "import xpress as xp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# --------------------------- USER CONFIG ---------------------------\n",
    "POIS_PATH = 'reduced_pois2.csv'\n",
    "STATIONS_TEMPLATE = 'candidate_stations_P300_type_{}.csv'\n",
    "DEMAND_TEMPLATE = 'poi_demand_per_hour_type_{}_cluster{}.csv'\n",
    "EXISTING_STATION_DATA = 'station_data.csv'\n",
    "\n",
    "STRATEGIES = ['uniform', 'commercial', 'pred']\n",
    "\n",
    "INITIAL_BUDGET = 5_000_000\n",
    "MIN_BUDGET = 100_000\n",
    "BUDGET_STEP = 300_000\n",
    "\n",
    "Tau = 2\n",
    "k = 1000\n",
    "\n",
    "COST_EXISTING = 60000\n",
    "COST_NEW = 90000\n",
    "ALPHA = 0.7\n",
    "\n",
    "W_C = {\n",
    "    'library': 1,\n",
    "    'residential': 1,\n",
    "    'school': 1,\n",
    "    'commercial': 1,\n",
    "    'university': 1,\n",
    "    'hospital': 1\n",
    "}\n",
    "\n",
    "XPRESS_VERBOSE = False\n",
    "OUTPUT_DIR = 'pareto_outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --------------------------- UTILITIES ---------------------------\n",
    "\n",
    "def haversine_matrix(pois: pd.DataFrame,\n",
    "                     stations: pd.DataFrame,\n",
    "                     poi_lat: str = 'lat', poi_lon: str = 'lon',\n",
    "                     st_lat: str = 'centroid_lat', st_lon: str = 'centroid_lon') -> np.ndarray:\n",
    "    \"\"\"Compute POI x Station distance matrix (km).\"\"\"\n",
    "    poi_coords = pois[[poi_lat, poi_lon]].to_numpy()\n",
    "    st_coords = stations[[st_lat, st_lon]].to_numpy()\n",
    "    lat1 = np.radians(poi_coords[:, 0])[:, None]\n",
    "    lon1 = np.radians(poi_coords[:, 1])[:, None]\n",
    "    lat2 = np.radians(st_coords[:, 0])[None, :]\n",
    "    lon2 = np.radians(st_coords[:, 1])[None, :]\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    R = 6371.0\n",
    "    return R * c\n",
    "\n",
    "# --------------------------- MODEL BUILDER ---------------------------\n",
    "\n",
    "def build_and_solve_model(distance_matrix_km: np.ndarray,\n",
    "                          stations: pd.DataFrame,\n",
    "                          pois: pd.DataFrame,\n",
    "                          demand_scenarios: List[List[float]],\n",
    "                          capacity_vector: np.ndarray,\n",
    "                          cost_vector: np.ndarray,\n",
    "                          I_c: Dict[str, List[int]],\n",
    "                          w_c: Dict[str, float],\n",
    "                          Tau: float,\n",
    "                          k: float,\n",
    "                          budget_limit: float,\n",
    "                          verbose: bool = False) -> Optional[Dict]:\n",
    "    I, J = distance_matrix_km.shape\n",
    "    prob = xp.problem(name='pcentre_modular_run')\n",
    "\n",
    "    # Variables\n",
    "    Y = {j: prob.addVariable(vartype=xp.binary, name=f'Y_{j}') for j in range(J)}\n",
    "    X = {(i, j): prob.addVariable(vartype=xp.binary, name=f'X_{i}_{j}') for i in range(I) for j in range(J)}\n",
    "    Z = {j: prob.addVariable(vartype=xp.integer, name=f'Z_{j}') for j in range(J)}\n",
    "    Q = prob.addVariable(name='Q', lb=0)\n",
    "\n",
    "    # Constraints\n",
    "    for i in range(I):\n",
    "        prob.addConstraint(xp.Sum(X[i, j] for j in range(J)) <= 1)\n",
    "\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            prob.addConstraint(X[i, j] <= Y[j])\n",
    "\n",
    "    for i in range(I):\n",
    "        prob.addConstraint(xp.Sum(distance_matrix_km[i, j] * X[i, j] for j in range(J)) <= Q)\n",
    "\n",
    "    prob.addConstraint(\n",
    "        xp.Sum(cost_vector[j] * Y[j] for j in range(J))\n",
    "        + k * xp.Sum((Z[j] - capacity_vector[j] * Y[j]) for j in range(J))\n",
    "        <= budget_limit\n",
    "    )\n",
    "\n",
    "    for j in range(J):\n",
    "        prob.addConstraint(Z[j] >= capacity_vector[j] * Y[j])\n",
    "        prob.addConstraint(Z[j] <= 100 * Y[j])\n",
    "        for s in range(len(demand_scenarios)):\n",
    "            ds = demand_scenarios[s]\n",
    "            prob.addConstraint(xp.Sum(X[i, j] * ds[i] for i in range(I)) <= Tau * Z[j])\n",
    "\n",
    "    for s in range(len(demand_scenarios)):\n",
    "        ds = demand_scenarios[s]\n",
    "        # Option B: Binary hit-based service level (% of POIs in category served)\n",
    "        for c, idx_list in I_c.items():\n",
    "            if not idx_list:\n",
    "                continue\n",
    "            lhs = xp.Sum(xp.Sum(X[i, j] for j in range(J)) for i in idx_list)\n",
    "            rhs = w_c[c] * len(idx_list)\n",
    "            prob.addConstraint(lhs >= rhs)\n",
    "\n",
    "    prob.setObjective(Q, sense=xp.minimize)\n",
    "\n",
    "    xp.setOutputEnabled(verbose)\n",
    "    try:\n",
    "        prob.solve()\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print('Solver failed:', e)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        Q_val = prob.getSolution(Q)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    Y_sol = np.array([prob.getSolution(Y[j]) for j in range(J)])\n",
    "    Z_sol = np.array([prob.getSolution(Z[j]) for j in range(J)])\n",
    "\n",
    "    budget_used = float(np.dot(cost_vector, Y_sol) + k * np.sum(Z_sol - capacity_vector * Y_sol))\n",
    "    opened_count = int((Y_sol > 0.5).sum())\n",
    "\n",
    "    opened_indices = [int(j) for j in range(J) if Y_sol[j] > 0.5]\n",
    "    Z_values_opened = {int(j): int(Z_sol[j]) for j in opened_indices}\n",
    "\n",
    "    X_sol = {(i, j): prob.getSolution(X[(i, j)]) for i in range(I) for j in range(J)}\n",
    "\n",
    "    # Build solution matrix\n",
    "    solution_matrix = np.zeros((I, J))\n",
    "    for (i, j), val in X_sol.items():\n",
    "        solution_matrix[i, j] = val\n",
    "\n",
    "    # Assign each POI to the station with max X_ij\n",
    "    assignments = np.argmax(solution_matrix, axis=1)\n",
    "\n",
    "    return {'problem': prob,\n",
    "            'Q': Q_val,\n",
    "            'Y_sol': Y_sol,\n",
    "            'Z_sol': Z_sol,\n",
    "            'X_sol': X_sol,\n",
    "            'solution_matrix': solution_matrix,\n",
    "            'assignments': assignments,\n",
    "            'budget_used': budget_used,\n",
    "            'opened': opened_count,\n",
    "            'opened_indices': opened_indices,\n",
    "            'Z_values_opened': Z_values_opened}\n",
    "\n",
    "# --------------------------- PARETO FOR STRATEGY (logged + store) ---------------------------\n",
    "\n",
    "def pareto_for_strategy_store(strategy: str,\n",
    "                              pois_path: str,\n",
    "                              stations_template: str,\n",
    "                              demand_template: str,\n",
    "                              existing_station_data_path: str,\n",
    "                              initial_budget: int = INITIAL_BUDGET,\n",
    "                              min_budget: int = MIN_BUDGET,\n",
    "                              budget_step: int = BUDGET_STEP,\n",
    "                              Tau: float = Tau,\n",
    "                              k: float = k,\n",
    "                              w_c: Dict[str, float] = W_C,\n",
    "                              alpha: float = ALPHA,\n",
    "                              cost_existing: float = COST_EXISTING,\n",
    "                              cost_new: float = COST_NEW,\n",
    "                              verbose: bool = XPRESS_VERBOSE) -> Optional[pd.DataFrame]:\n",
    "    pois = pd.read_csv(pois_path)\n",
    "    stations = pd.read_csv(stations_template.format(strategy))\n",
    "    D_km = haversine_matrix(pois, stations)\n",
    "\n",
    "    # nearest-POI category assignment\n",
    "    poi_categories = pois['category'].reset_index(drop=True)\n",
    "    min_row_idx_for_station = np.argmin(D_km, axis=0)\n",
    "    station_categories = poi_categories.iloc[min_row_idx_for_station].reset_index(drop=True)\n",
    "    stations['category'] = station_categories.values\n",
    "\n",
    "    categories = list(w_c.keys())\n",
    "    I_c = {c: pois.index[pois['category'] == c].tolist() for c in categories}\n",
    "\n",
    "    demand_scenarios: List[List[float]] = []\n",
    "    for i in range(4):\n",
    "        df = pd.read_csv(demand_template.format(strategy, i))\n",
    "        demand_scenarios.append(df['demand_per_hour'].tolist())\n",
    "\n",
    "    existing_data = pd.read_csv(existing_station_data_path)\n",
    "    capacity_map = dict(zip(existing_data['station_id'], existing_data['capacity']))\n",
    "    capacity_vector = np.array([capacity_map.get(sid, 10) for sid in stations['snapped_station_id']])\n",
    "\n",
    "    is_existing = stations['is_existing_station'].astype(bool).values\n",
    "    station_is_commercial_by_nearest = (stations['category'] == 'commercial').values\n",
    "\n",
    "    J = stations.shape[0]\n",
    "    cost_vector = np.zeros(J, dtype=float)\n",
    "    for j in range(J):\n",
    "        if is_existing[j] and station_is_commercial_by_nearest[j]:\n",
    "            cost_vector[j] = alpha * cost_existing\n",
    "        elif is_existing[j]:\n",
    "            cost_vector[j] = cost_existing\n",
    "        elif station_is_commercial_by_nearest[j]:\n",
    "            cost_vector[j] = alpha * cost_new\n",
    "        else:\n",
    "            cost_vector[j] = cost_new\n",
    "\n",
    "    # Budgets descending (high -> low)\n",
    "    budgets = list(range(int(initial_budget), int(min_budget) - 1, -int(budget_step)))\n",
    "    results = []\n",
    "    detailed_solutions = []\n",
    "\n",
    "    for b in budgets:\n",
    "        print(f\"[Strategy={strategy}] Attempting budget limit = £{b:,}\")\n",
    "        sol = build_and_solve_model(D_km, stations, pois, demand_scenarios,\n",
    "                                    capacity_vector, cost_vector, I_c, w_c,\n",
    "                                    Tau, k, float(b), verbose=verbose)\n",
    "        if sol is None:\n",
    "            print(f\"[Strategy={strategy}] No feasible solution at budget £{b:,}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[Strategy={strategy}] Solved: budget_limit=£{b:,} -> budget_used=£{sol['budget_used']:.2f}, Q={sol['Q']:.4f} km, opened={sol['opened']} stations\")\n",
    "\n",
    "        results.append({'strategy': strategy, 'budget_limit': b, 'budget_used': sol['budget_used'], 'Q': sol['Q'], 'opened': sol['opened']})\n",
    "\n",
    "        detailed_solutions.append({\n",
    "            'strategy': strategy,\n",
    "            'budget_limit': int(b),\n",
    "            'budget_used': float(sol['budget_used']),\n",
    "            'Q': float(sol['Q']),\n",
    "            'opened_count': int(sol['opened']),\n",
    "            'opened_indices': sol['opened_indices'],\n",
    "            'Z_values_opened': sol['Z_values_opened']\n",
    "        })\n",
    "\n",
    "    # Save detailed solutions\n",
    "    if detailed_solutions:\n",
    "        det_csv = os.path.join(OUTPUT_DIR, f'detailed_solutions_{strategy}.csv')\n",
    "        det_pkl = os.path.join(OUTPUT_DIR, f'detailed_solutions_{strategy}.pkl')\n",
    "        pd.DataFrame(detailed_solutions).to_csv(det_csv, index=False)\n",
    "        with open(det_pkl, 'wb') as f:\n",
    "            pickle.dump(detailed_solutions, f)\n",
    "        print(f\"Saved detailed solutions for strategy {strategy} to {det_csv} and {det_pkl}\")\n",
    "\n",
    "    if len(results) == 0:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values('budget_used', ascending=True).reset_index(drop=True)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, f'pareto_points_{strategy}.csv'), index=False)\n",
    "    print(f\"Saved pareto points for strategy {strategy} to {os.path.join(OUTPUT_DIR, f'pareto_points_{strategy}.csv')}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# --------------------------- DOMINATION CHECK ---------------------------\n",
    "\n",
    "def find_nondominated(df_all: pd.DataFrame) -> pd.DataFrame:\n",
    "    pts = df_all[['budget_used', 'Q']].to_numpy()\n",
    "    n = pts.shape[0]\n",
    "    is_nd = np.ones(n, dtype=bool)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if (pts[j, 0] <= pts[i, 0] and pts[j, 1] <= pts[i, 1]) and (pts[j, 0] < pts[i, 0] or pts[j, 1] < pts[i, 1]):\n",
    "                is_nd[i] = False\n",
    "                break\n",
    "    return df_all[is_nd].reset_index(drop=True)\n",
    "\n",
    "# --------------------------- MAIN: RUN ALL + PLOT + STORE DOMINANT ---------------------------\n",
    "\n",
    "def run_all_and_store_dominant(strategies: List[str] = STRATEGIES):\n",
    "    per_strategy_dfs: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for s in strategies:\n",
    "        print('\\n' + '=' * 70)\n",
    "        print(f\"Starting strategy: {s}\")\n",
    "        df = pareto_for_strategy_store(s, POIS_PATH, STATIONS_TEMPLATE, DEMAND_TEMPLATE, EXISTING_STATION_DATA,\n",
    "                                      initial_budget=INITIAL_BUDGET, min_budget=MIN_BUDGET, budget_step=BUDGET_STEP,\n",
    "                                      Tau=Tau, k=k, w_c=W_C, alpha=ALPHA, cost_existing=COST_EXISTING,\n",
    "                                      cost_new=COST_NEW, verbose=XPRESS_VERBOSE)\n",
    "        if df is None or df.empty:\n",
    "            print(f\"Strategy {s} produced no feasible points.\")\n",
    "            continue\n",
    "        per_strategy_dfs[s] = df\n",
    "\n",
    "    # Save per-strategy files already saved in function; combine\n",
    "    all_dfs: List[pd.DataFrame] = []\n",
    "    for s, df in per_strategy_dfs.items():\n",
    "        tmp = df.copy()\n",
    "        tmp['strategy'] = s\n",
    "        all_dfs.append(tmp)\n",
    "\n",
    "    if not all_dfs:\n",
    "        print('No solutions found across strategies.')\n",
    "        return\n",
    "\n",
    "    df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "    df_all_path = os.path.join(OUTPUT_DIR, 'pareto_points_all_strategies.csv')\n",
    "    df_all.to_csv(df_all_path, index=False)\n",
    "    print(f'Saved all pareto points to {df_all_path}')\n",
    "\n",
    "    # Find non-dominated\n",
    "    df_nd = find_nondominated(df_all)\n",
    "    nd_path = os.path.join(OUTPUT_DIR, 'pareto_points_nondominated.csv')\n",
    "    df_nd.to_csv(nd_path, index=False)\n",
    "    print(f'Saved nondominated (global Pareto) points to {nd_path}')\n",
    "\n",
    "    # Save detailed dominant solutions from per-strategy pickles\n",
    "    dominant_details = []\n",
    "    for _, row in df_nd.iterrows():\n",
    "        strat = row['strategy']\n",
    "        pkl_path = os.path.join(OUTPUT_DIR, f'detailed_solutions_{strat}.pkl')\n",
    "        if not os.path.exists(pkl_path):\n",
    "            continue\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            det_list = pickle.load(f)\n",
    "        # find entry with closest budget_used\n",
    "        best = None\n",
    "        min_diff = float('inf')\n",
    "        for det in det_list:\n",
    "            diff = abs(det['budget_used'] - row['budget_used'])\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                best = det\n",
    "        if best is not None:\n",
    "            best_copy = best.copy()\n",
    "            best_copy['strategy'] = strat\n",
    "            dominant_details.append(best_copy)\n",
    "\n",
    "    dominant_csv = os.path.join(OUTPUT_DIR, 'dominant_solutions_detailed.csv')\n",
    "    dominant_pkl = os.path.join(OUTPUT_DIR, 'dominant_solutions_detailed.pkl')\n",
    "    if dominant_details:\n",
    "        pd.DataFrame(dominant_details).to_csv(dominant_csv, index=False)\n",
    "        with open(dominant_pkl, 'wb') as f:\n",
    "            pickle.dump(dominant_details, f)\n",
    "        print(f'Saved dominant solution details to {dominant_csv} and {dominant_pkl}')\n",
    "    else:\n",
    "        print('No detailed dominant solutions found to save')\n",
    "\n",
    "    # Side-by-side plot\n",
    "    n = len(strategies)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(6 * n, 5), sharey=True)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for ax, s in zip(axes, strategies):\n",
    "        df = per_strategy_dfs.get(s)\n",
    "        if df is None or df.empty:\n",
    "            ax.set_title(s + ' (no points)')\n",
    "            continue\n",
    "        ax.scatter(df['budget_used'], df['Q'], marker='o')\n",
    "        for _, row in df.iterrows():\n",
    "            ax.annotate(f\"Q={row['Q']:.3f}\\n£{row['budget_used']:.0f}\\nopen={row['opened']}\",\n",
    "                        (row['budget_used'], row['Q']), textcoords='offset points', xytext=(3, 3), fontsize=8)\n",
    "        ax.set_title(s)\n",
    "        ax.set_xlabel('Budget used (£)')\n",
    "        ax.grid(True)\n",
    "    axes[0].set_ylabel('Q (km)')\n",
    "    plt.suptitle('Per-strategy Pareto points (Budget used vs Q)')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    side_by_side_path = os.path.join(OUTPUT_DIR, 'pareto_per_strategy_side_by_side.png')\n",
    "    plt.savefig(side_by_side_path, dpi=200)\n",
    "    print(f'Saved side-by-side figure: {side_by_side_path}')\n",
    "\n",
    "    # Combined plot with nondominated highlighted\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    for s in strategies:\n",
    "        sub = df_all[df_all['strategy'] == s]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        plt.scatter(sub['budget_used'], sub['Q'], label=s, alpha=0.4)\n",
    "    if not df_nd.empty:\n",
    "        plt.scatter(df_nd['budget_used'], df_nd['Q'], color='red', s=100, label='Global Pareto (nondominated)')\n",
    "        for _, row in df_nd.iterrows():\n",
    "            plt.annotate(f\"{row['strategy']}\\nQ={row['Q']:.3f}\\n£{row['budget_used']:.0f}\",\n",
    "                         (row['budget_used'], row['Q']), textcoords='offset points', xytext=(5, -5), fontsize=9)\n",
    "    plt.xlabel('Budget used (£)')\n",
    "    plt.ylabel('Q (km)')\n",
    "    plt.title('Combined solutions and global Pareto (nondominated)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    combined_path = os.path.join(OUTPUT_DIR, 'pareto_combined_nondominated.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(combined_path, dpi=200)\n",
    "    print(f'Saved combined Pareto figure with nondominated highlighted: {combined_path}')\n",
    "\n",
    "    print('\\nGLOBAL NONDOMINATED SOLUTIONS:')\n",
    "    print(df_nd)\n",
    "    print('\\nDetailed dominant solutions saved (if any) to:')\n",
    "    print(dominant_csv)\n",
    "    print(dominant_pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6affbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "alpha_sensitivity_vs_uniform.py\n",
    "\n",
    "Find values of alpha (cost scaling factor) at which commercial and pred strategies\n",
    "become more worthwhile than uniform, under a fixed budget.\n",
    "\n",
    "Comparison rule (Option C - dominance): strategy S is \"preferred\" over uniform if\n",
    "both\n",
    "  Q_S <= Q_uniform and budget_used_S <= budget_used_uniform\n",
    "and at least one of those inequalities is strict.\n",
    "\n",
    "Outputs:\n",
    " - CSV with alpha, Q and budget for each strategy and boolean flags indicating dominance\n",
    " - Plot Q vs alpha for the three strategies with markers where dominance occurs\n",
    "\n",
    "Usage: python alpha_sensitivity_vs_uniform.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "\n",
    "OUTPUT_DIR = 'pareto_outputs'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------- User settings --------------------\n",
    "strategy_list = ['uniform', 'commercial', 'pred']\n",
    "fixed_budget = 6_750_000  # change if you want a different budget\n",
    "alpha_grid = np.linspace(0.01, 1.0, 15)  # grid of alpha to test\n",
    "\n",
    "# -------------------- Data loader (copied logic from pipeline) --------------------\n",
    "\n",
    "def load_data_for_strategy(strategy: str):\n",
    "    pois = pd.read_csv(POIS_PATH)\n",
    "    stations = pd.read_csv(STATIONS_TEMPLATE.format(strategy))\n",
    "    D_km = haversine_matrix(pois, stations)\n",
    "\n",
    "    poi_categories = pois['category'].reset_index(drop=True)\n",
    "    min_row_idx_for_station = np.argmin(D_km, axis=0)\n",
    "    station_categories = poi_categories.iloc[min_row_idx_for_station].reset_index(drop=True)\n",
    "    stations['category'] = station_categories.values\n",
    "\n",
    "    categories = list(W_C.keys())\n",
    "    I_c = {c: pois.index[pois['category'] == c].tolist() for c in categories}\n",
    "\n",
    "    demand_scenarios: List[List[float]] = []\n",
    "    for i in range(4):\n",
    "        df = pd.read_csv(DEMAND_TEMPLATE.format(strategy, i))\n",
    "        demand_scenarios.append(df['demand_per_hour'].tolist())\n",
    "\n",
    "    existing_data = pd.read_csv(EXISTING_STATION_DATA)\n",
    "    capacity_map = dict(zip(existing_data['station_id'], existing_data['capacity']))\n",
    "    capacity_vector = np.array([capacity_map.get(sid, 10) for sid in stations['snapped_station_id']])\n",
    "\n",
    "    is_existing = stations['is_existing_station'].astype(bool).values\n",
    "    station_is_commercial_by_nearest = (stations['category'] == 'commercial').values\n",
    "\n",
    "    return {\n",
    "        'pois': pois,\n",
    "        'stations': stations,\n",
    "        'D_km': D_km,\n",
    "        'I_c': I_c,\n",
    "        'demand_scenarios': demand_scenarios,\n",
    "        'capacity_vector': capacity_vector,\n",
    "        'is_existing': is_existing,\n",
    "        'station_is_commercial_by_nearest': station_is_commercial_by_nearest\n",
    "    }\n",
    "\n",
    "# -------------------- helper: build cost vector for alpha --------------------\n",
    "\n",
    "def build_cost_vector(alpha: float, is_existing: np.ndarray, station_is_commercial_by_nearest: np.ndarray) -> np.ndarray:\n",
    "    J = len(is_existing)\n",
    "    cost_vector = np.zeros(J, dtype=float)\n",
    "    for j in range(J):\n",
    "        if is_existing[j] and station_is_commercial_by_nearest[j]:\n",
    "            cost_vector[j] = alpha * COST_EXISTING\n",
    "        elif is_existing[j]:\n",
    "            cost_vector[j] = COST_EXISTING\n",
    "        elif station_is_commercial_by_nearest[j]:\n",
    "            cost_vector[j] = alpha * COST_NEW\n",
    "        else:\n",
    "            cost_vector[j] = COST_NEW\n",
    "    return cost_vector\n",
    "\n",
    "# -------------------- run sensitivity --------------------\n",
    "\n",
    "def run_alpha_dominance_analysis(fixed_budget: float, alpha_grid: np.ndarray):\n",
    "    # load data for one representative strategy fileset (station files differ by strategy)\n",
    "    # We need to load stations per strategy because stations CSV path uses strategy name.\n",
    "    # For fairness we'll load station files separately inside the loop when necessary.\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for alpha in alpha_grid:\n",
    "        row = {'alpha': float(alpha)}\n",
    "        strategy_results = {}\n",
    "        for s in strategy_list:\n",
    "            # load data for this strategy (stations file differs)\n",
    "            data = load_data_for_strategy(s)\n",
    "            pois = data['pois']\n",
    "            stations = data['stations']\n",
    "            D_km = data['D_km']\n",
    "            I_c = data['I_c']\n",
    "            demand_scenarios = data['demand_scenarios']\n",
    "            capacity_vector = data['capacity_vector']\n",
    "            is_existing = data['is_existing']\n",
    "            station_is_commercial_by_nearest = data['station_is_commercial_by_nearest']\n",
    "\n",
    "            cost_vector = build_cost_vector(alpha, is_existing, station_is_commercial_by_nearest)\n",
    "\n",
    "            sol = build_and_solve_model(\n",
    "                D_km, stations, pois, demand_scenarios, capacity_vector,\n",
    "                cost_vector, I_c, W_C, Tau, k, float(fixed_budget), verbose=False\n",
    "            )\n",
    "\n",
    "            if sol is None:\n",
    "                strategy_results[s] = {'feasible': False, 'Q': np.nan, 'budget_used': np.nan, 'opened': np.nan}\n",
    "            else:\n",
    "                strategy_results[s] = {'feasible': True, 'Q': float(sol['Q']), 'budget_used': float(sol['budget_used']), 'opened': int(sol['opened'])}\n",
    "\n",
    "            # add to row\n",
    "            row[f'{s}_feasible'] = strategy_results[s]['feasible']\n",
    "            row[f'{s}_Q'] = strategy_results[s]['Q']\n",
    "            row[f'{s}_budget_used'] = strategy_results[s]['budget_used']\n",
    "            row[f'{s}_opened'] = strategy_results[s]['opened']\n",
    "\n",
    "        # dominance check relative to uniform (Option C)\n",
    "        # requires feasible for both\n",
    "        u = strategy_results['uniform']\n",
    "        for s in ['commercial', 'pred']:\n",
    "            v = strategy_results[s]\n",
    "            dominates = False\n",
    "            if u['feasible'] and v['feasible']:\n",
    "                leqQ = (v['Q'] <= u['Q'])\n",
    "                leqB = (v['budget_used'] <= u['budget_used'])\n",
    "                strict = (v['Q'] < u['Q']) or (v['budget_used'] < u['budget_used'])\n",
    "                dominates = bool(leqQ and leqB and strict)\n",
    "            row[f'{s}_dominates_uniform'] = dominates\n",
    "\n",
    "        records.append(row)\n",
    "        print(f'alpha={alpha:.3f}: commercial dominates uniform={row[\"commercial_dominates_uniform\"]}, pred dominates uniform={row[\"pred_dominates_uniform\"]}')\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "# -------------------- plotting & reporting --------------------\n",
    "\n",
    "def plot_results(df: pd.DataFrame, out_prefix: str):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for s in strategy_list:\n",
    "        feasible_mask = df[f'{s}_feasible'] == True\n",
    "        plt.plot(df.loc[feasible_mask, 'alpha'], df.loc[feasible_mask, f'{s}_Q'], marker='o', label=s)\n",
    "    # mark alphas where dominance occurs\n",
    "    comm_dom = df[df['commercial_dominates_uniform'] == True]['alpha']\n",
    "    pred_dom = df[df['pred_dominates_uniform'] == True]['alpha']\n",
    "    if not comm_dom.empty:\n",
    "        plt.scatter(comm_dom, np.interp(comm_dom, df['alpha'], df['commercial_Q']), color='C1', s=120, marker='*', label='commercial dominates')\n",
    "    if not pred_dom.empty:\n",
    "        plt.scatter(pred_dom, np.interp(pred_dom, df['alpha'], df['pred_Q']), color='C2', s=120, marker='P', label='pred dominates')\n",
    "\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('Optimal Q (km)')\n",
    "    plt.title(f'Alpha sensitivity and dominance vs uniform (budget={fixed_budget:,.0f})')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(OUTPUT_DIR, f'{out_prefix}_alpha_vs_Q.png')\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    print(f'Saved plot to {out_png}')\n",
    "\n",
    "    # Save CSV\n",
    "    out_csv = os.path.join(OUTPUT_DIR, f'{out_prefix}_alpha_dominance.csv')\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f'Saved CSV to {out_csv}')\n",
    "\n",
    "    # Report alpha thresholds: first alpha where dominance is True (if any)\n",
    "    comm_first = df[df['commercial_dominates_uniform'] == True]['alpha']\n",
    "    pred_first = df[df['pred_dominates_uniform'] == True]['alpha']\n",
    "    print('Thresholds:')\n",
    "    print('commercial first dominates at alpha=', float(comm_first.iloc[0]) if not comm_first.empty else 'never in grid')\n",
    "    print('pred first dominates at alpha=', float(pred_first.iloc[0]) if not pred_first.empty else 'never in grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038d0e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/v19h6ld131n5p0bkj6b850sr0000gn/T/ipykernel_82505/331104810.py:79: LicenseWarning: Using the license file found in your Xpress installation. If you want to use this license and no longer want to see this message, use the following code before using the xpress module:\n",
      "  xpress.init('/Applications/FICO Xpress/xpressmp/bin/xpauth.xpr')\n",
      "  prob = xp.problem(name='pcentre_modular_run')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved as uniform_strategy_map_budget_8105409.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium import Circle, PolyLine\n",
    "\n",
    "# Step 1: Load data\n",
    "data = load_data_for_strategy('uniform')\n",
    "pois = data['pois']\n",
    "stations = data['stations']\n",
    "D_km = data['D_km']\n",
    "I_c = data['I_c']\n",
    "demand_scenarios = data['demand_scenarios']\n",
    "capacity_vector = data['capacity_vector']\n",
    "is_existing = data['is_existing']\n",
    "station_is_commercial_by_nearest = data['station_is_commercial_by_nearest']\n",
    "\n",
    "# Step 2: Compute cost vector as in your pipeline\n",
    "alpha = ALPHA\n",
    "cost_vector = np.zeros(stations.shape[0], dtype=float)\n",
    "for j in range(stations.shape[0]):\n",
    "    if is_existing[j] and station_is_commercial_by_nearest[j]:\n",
    "        cost_vector[j] = alpha * COST_EXISTING\n",
    "    elif is_existing[j]:\n",
    "        cost_vector[j] = COST_EXISTING\n",
    "    elif station_is_commercial_by_nearest[j]:\n",
    "        cost_vector[j] = alpha * COST_NEW\n",
    "    else:\n",
    "        cost_vector[j] = COST_NEW\n",
    "\n",
    "# Step 3: Solve model at target budget\n",
    "sol = build_and_solve_model(D_km, stations, pois, demand_scenarios,\n",
    "                            capacity_vector, cost_vector, I_c, W_C,\n",
    "                            Tau, k, fixed_budget, verbose=False)\n",
    "\n",
    "if sol is None:\n",
    "    print(f\"No feasible solution found for budget £{fixed_budget}\")\n",
    "else:\n",
    "    # Extract variables for mapping\n",
    "    X_sol = sol['X_sol']\n",
    "    I, J = D_km.shape\n",
    "\n",
    "    # Build assignment matrix\n",
    "    solution_matrix = np.zeros((I, J))\n",
    "    for (i, j), val in X_sol.items():\n",
    "        solution_matrix[i, j] = val\n",
    "\n",
    "    # Assign each POI to station with max X_ij\n",
    "    assignments = solution_matrix.argmax(axis=1)\n",
    "\n",
    "    stations_open = sol['opened_indices']\n",
    "\n",
    "    # Step 4: Plot map function\n",
    "    def plot_station_poi_map(pois, stations, distance_matrix, station_indices_open, assignments, map_filename='stations_with_lines_map.html'):\n",
    "        map_center = (pois['lat'].mean(), pois['lon'].mean())\n",
    "        m = folium.Map(location=map_center, zoom_start=13)\n",
    "\n",
    "        for station_idx in station_indices_open:\n",
    "            station_lat = stations.iloc[station_idx]['centroid_lat']\n",
    "            station_lon = stations.iloc[station_idx]['centroid_lon']\n",
    "\n",
    "            # POIs served by this station\n",
    "            served_pois = [i for i, j in enumerate(assignments) if j == station_idx]\n",
    "\n",
    "            max_distance_km = max((distance_matrix[i, station_idx] for i in served_pois), default=0.1)\n",
    "\n",
    "            folium.Marker(\n",
    "                location=(station_lat, station_lon),\n",
    "                popup=f\"Station {stations.iloc[station_idx]['candidate_id']}\",\n",
    "                icon=folium.Icon(color='darkgreen', icon='bicycle', prefix='fa')\n",
    "            ).add_to(m)\n",
    "\n",
    "            Circle(\n",
    "                location=(station_lat, station_lon),\n",
    "                radius=max_distance_km * 1000,\n",
    "                color='blue',\n",
    "                fill=True,\n",
    "                fill_opacity=0.1,\n",
    "                weight=2,\n",
    "                popup=f\"Coverage area: {max_distance_km:.2f} km\"\n",
    "            ).add_to(m)\n",
    "\n",
    "            for poi_idx in served_pois:\n",
    "                poi_lat = pois.iloc[poi_idx]['lat']\n",
    "                poi_lon = pois.iloc[poi_idx]['lon']\n",
    "\n",
    "                folium.CircleMarker(\n",
    "                    location=(poi_lat, poi_lon),\n",
    "                    radius=5,\n",
    "                    weight=3,\n",
    "                    color='brown',\n",
    "                    fill=True,\n",
    "                    fill_opacity=1,\n",
    "                    popup=f\"POI {pois.iloc[poi_idx]['poi_id']}\"\n",
    "                ).add_to(m)\n",
    "\n",
    "                PolyLine([(station_lat, station_lon), (poi_lat, poi_lon)],\n",
    "                         color='black', weight=3, opacity=0.7\n",
    "                ).add_to(m)\n",
    "\n",
    "        m.save(map_filename)\n",
    "        print(f\"Map saved as {map_filename}\")\n",
    "\n",
    "    # Generate map\n",
    "    plot_station_poi_map(pois, stations, D_km, stations_open, assignments, 'uniform_strategy_map_budget_8105409.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a06068",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_open = []\n",
    "Y_sol=sol['Y_sol']\n",
    "for j in range(J):\n",
    "    if Y_sol[j] > 0.5:  # Binary variable, so > 0.5 means 1\n",
    "        stations_open.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b18825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. STATIONS TO OPEN (83 out of 383):\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n1. STATIONS TO OPEN ({len(stations_open)} out of {J}):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6978b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6750000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol['budget_used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19bbd128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1991829890904042"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8535fb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'library': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43],\n",
       " 'residential': [240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  266,\n",
       "  267,\n",
       "  268,\n",
       "  269,\n",
       "  270,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  286,\n",
       "  287,\n",
       "  288,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  294,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  308,\n",
       "  309,\n",
       "  310,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  315,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  319,\n",
       "  320,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  324,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  330,\n",
       "  331,\n",
       "  332,\n",
       "  333,\n",
       "  334,\n",
       "  335,\n",
       "  336,\n",
       "  337,\n",
       "  338,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  343,\n",
       "  344,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  348,\n",
       "  349,\n",
       "  350,\n",
       "  351,\n",
       "  352,\n",
       "  353,\n",
       "  354,\n",
       "  355,\n",
       "  356,\n",
       "  357,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  363,\n",
       "  364,\n",
       "  365,\n",
       "  366,\n",
       "  367,\n",
       "  368,\n",
       "  369,\n",
       "  370,\n",
       "  371,\n",
       "  372,\n",
       "  373,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  378,\n",
       "  379,\n",
       "  380,\n",
       "  381,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  386,\n",
       "  387,\n",
       "  388,\n",
       "  389,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  393,\n",
       "  394,\n",
       "  395,\n",
       "  396,\n",
       "  397,\n",
       "  398,\n",
       "  399,\n",
       "  400,\n",
       "  401,\n",
       "  402,\n",
       "  403,\n",
       "  404,\n",
       "  405,\n",
       "  406,\n",
       "  407,\n",
       "  408,\n",
       "  409,\n",
       "  410,\n",
       "  411,\n",
       "  412,\n",
       "  413,\n",
       "  414,\n",
       "  415,\n",
       "  416,\n",
       "  417,\n",
       "  418,\n",
       "  419,\n",
       "  420,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  424,\n",
       "  425,\n",
       "  426,\n",
       "  427,\n",
       "  428,\n",
       "  429,\n",
       "  430,\n",
       "  431,\n",
       "  432,\n",
       "  433,\n",
       "  434,\n",
       "  435,\n",
       "  436,\n",
       "  437,\n",
       "  438,\n",
       "  439,\n",
       "  440,\n",
       "  441,\n",
       "  442,\n",
       "  443,\n",
       "  444,\n",
       "  445,\n",
       "  446,\n",
       "  447,\n",
       "  448,\n",
       "  449,\n",
       "  450,\n",
       "  451,\n",
       "  452,\n",
       "  453,\n",
       "  454,\n",
       "  455,\n",
       "  456,\n",
       "  457,\n",
       "  458,\n",
       "  459,\n",
       "  460,\n",
       "  461,\n",
       "  462,\n",
       "  463,\n",
       "  464,\n",
       "  465,\n",
       "  466,\n",
       "  467,\n",
       "  468,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  476,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  480,\n",
       "  481,\n",
       "  482,\n",
       "  483,\n",
       "  484,\n",
       "  485,\n",
       "  486,\n",
       "  487,\n",
       "  488,\n",
       "  489,\n",
       "  490,\n",
       "  491,\n",
       "  492,\n",
       "  493,\n",
       "  494,\n",
       "  495,\n",
       "  496,\n",
       "  497,\n",
       "  498,\n",
       "  499,\n",
       "  500,\n",
       "  501,\n",
       "  502,\n",
       "  503,\n",
       "  504,\n",
       "  505,\n",
       "  506,\n",
       "  507,\n",
       "  508,\n",
       "  509,\n",
       "  510,\n",
       "  511,\n",
       "  512,\n",
       "  513,\n",
       "  514,\n",
       "  515,\n",
       "  516,\n",
       "  517,\n",
       "  518,\n",
       "  519,\n",
       "  520,\n",
       "  521,\n",
       "  522,\n",
       "  523,\n",
       "  524,\n",
       "  525,\n",
       "  526,\n",
       "  527,\n",
       "  528,\n",
       "  529,\n",
       "  530,\n",
       "  531,\n",
       "  532,\n",
       "  533,\n",
       "  534,\n",
       "  535,\n",
       "  536,\n",
       "  537,\n",
       "  538,\n",
       "  539,\n",
       "  540,\n",
       "  541,\n",
       "  542,\n",
       "  543,\n",
       "  544,\n",
       "  545,\n",
       "  546,\n",
       "  547,\n",
       "  548,\n",
       "  549,\n",
       "  550,\n",
       "  551,\n",
       "  552,\n",
       "  553,\n",
       "  554,\n",
       "  555,\n",
       "  556,\n",
       "  557,\n",
       "  558,\n",
       "  559,\n",
       "  560,\n",
       "  561,\n",
       "  562,\n",
       "  563,\n",
       "  564,\n",
       "  565,\n",
       "  566,\n",
       "  567,\n",
       "  568,\n",
       "  569,\n",
       "  570,\n",
       "  571,\n",
       "  572,\n",
       "  573,\n",
       "  574,\n",
       "  575,\n",
       "  576,\n",
       "  577,\n",
       "  578,\n",
       "  579,\n",
       "  580,\n",
       "  581,\n",
       "  582,\n",
       "  583,\n",
       "  584,\n",
       "  585,\n",
       "  586,\n",
       "  587,\n",
       "  588,\n",
       "  589,\n",
       "  590,\n",
       "  591,\n",
       "  592,\n",
       "  593,\n",
       "  594,\n",
       "  595,\n",
       "  596,\n",
       "  597,\n",
       "  598,\n",
       "  599,\n",
       "  600,\n",
       "  601,\n",
       "  602,\n",
       "  603,\n",
       "  604,\n",
       "  605,\n",
       "  606,\n",
       "  607,\n",
       "  608,\n",
       "  609,\n",
       "  610,\n",
       "  611,\n",
       "  612,\n",
       "  613,\n",
       "  614,\n",
       "  615,\n",
       "  616,\n",
       "  617,\n",
       "  618,\n",
       "  619,\n",
       "  620,\n",
       "  621,\n",
       "  622,\n",
       "  623,\n",
       "  624,\n",
       "  625,\n",
       "  626,\n",
       "  627,\n",
       "  628,\n",
       "  629,\n",
       "  630,\n",
       "  631,\n",
       "  632,\n",
       "  633,\n",
       "  634,\n",
       "  635,\n",
       "  636,\n",
       "  637,\n",
       "  638,\n",
       "  639,\n",
       "  640,\n",
       "  641,\n",
       "  642,\n",
       "  643,\n",
       "  644,\n",
       "  645,\n",
       "  646,\n",
       "  647,\n",
       "  648,\n",
       "  649,\n",
       "  650,\n",
       "  651,\n",
       "  652,\n",
       "  653,\n",
       "  654,\n",
       "  655,\n",
       "  656,\n",
       "  657,\n",
       "  658,\n",
       "  659,\n",
       "  660,\n",
       "  661,\n",
       "  662,\n",
       "  663,\n",
       "  664,\n",
       "  665,\n",
       "  666,\n",
       "  667,\n",
       "  668,\n",
       "  669,\n",
       "  670,\n",
       "  671,\n",
       "  672,\n",
       "  673,\n",
       "  674,\n",
       "  675,\n",
       "  676,\n",
       "  677,\n",
       "  678,\n",
       "  679,\n",
       "  680,\n",
       "  681,\n",
       "  682,\n",
       "  683,\n",
       "  684,\n",
       "  685,\n",
       "  686,\n",
       "  687,\n",
       "  688,\n",
       "  689,\n",
       "  690,\n",
       "  691,\n",
       "  692,\n",
       "  693,\n",
       "  694,\n",
       "  695,\n",
       "  696,\n",
       "  697,\n",
       "  698],\n",
       " 'school': [44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  216],\n",
       " 'commercial': [699,\n",
       "  700,\n",
       "  701,\n",
       "  702,\n",
       "  703,\n",
       "  704,\n",
       "  705,\n",
       "  706,\n",
       "  707,\n",
       "  708,\n",
       "  709,\n",
       "  710,\n",
       "  711,\n",
       "  712,\n",
       "  713,\n",
       "  714,\n",
       "  715,\n",
       "  716,\n",
       "  717,\n",
       "  718,\n",
       "  719,\n",
       "  720,\n",
       "  721,\n",
       "  722,\n",
       "  723,\n",
       "  724,\n",
       "  725,\n",
       "  726,\n",
       "  727,\n",
       "  728,\n",
       "  729,\n",
       "  730,\n",
       "  731,\n",
       "  732,\n",
       "  733,\n",
       "  734,\n",
       "  735,\n",
       "  736,\n",
       "  737,\n",
       "  738,\n",
       "  739,\n",
       "  740,\n",
       "  741,\n",
       "  742,\n",
       "  743,\n",
       "  744,\n",
       "  745,\n",
       "  746,\n",
       "  747,\n",
       "  748,\n",
       "  749,\n",
       "  750,\n",
       "  751,\n",
       "  752,\n",
       "  753,\n",
       "  754,\n",
       "  755,\n",
       "  756,\n",
       "  757,\n",
       "  758,\n",
       "  759,\n",
       "  760,\n",
       "  761,\n",
       "  762,\n",
       "  763,\n",
       "  764,\n",
       "  765,\n",
       "  766,\n",
       "  767,\n",
       "  768,\n",
       "  769,\n",
       "  770,\n",
       "  771,\n",
       "  772,\n",
       "  773,\n",
       "  774,\n",
       "  775,\n",
       "  776,\n",
       "  777,\n",
       "  778,\n",
       "  779,\n",
       "  780,\n",
       "  781,\n",
       "  782,\n",
       "  783,\n",
       "  784,\n",
       "  785,\n",
       "  786,\n",
       "  787,\n",
       "  788,\n",
       "  789,\n",
       "  790,\n",
       "  791,\n",
       "  792,\n",
       "  793,\n",
       "  794,\n",
       "  795,\n",
       "  796,\n",
       "  797,\n",
       "  798,\n",
       "  799,\n",
       "  800,\n",
       "  801,\n",
       "  802,\n",
       "  803,\n",
       "  804,\n",
       "  805,\n",
       "  806,\n",
       "  807,\n",
       "  808,\n",
       "  809,\n",
       "  810,\n",
       "  811,\n",
       "  812,\n",
       "  813,\n",
       "  814,\n",
       "  815,\n",
       "  816,\n",
       "  817,\n",
       "  818,\n",
       "  819,\n",
       "  820,\n",
       "  821,\n",
       "  822,\n",
       "  823,\n",
       "  824,\n",
       "  825,\n",
       "  826,\n",
       "  827,\n",
       "  828,\n",
       "  829,\n",
       "  830,\n",
       "  831,\n",
       "  832,\n",
       "  833,\n",
       "  834,\n",
       "  835,\n",
       "  836,\n",
       "  837,\n",
       "  838,\n",
       "  839,\n",
       "  840,\n",
       "  841,\n",
       "  842,\n",
       "  843,\n",
       "  844,\n",
       "  845,\n",
       "  846,\n",
       "  847,\n",
       "  848,\n",
       "  849,\n",
       "  850,\n",
       "  851,\n",
       "  852,\n",
       "  853,\n",
       "  854,\n",
       "  855,\n",
       "  856,\n",
       "  857,\n",
       "  858,\n",
       "  859,\n",
       "  860,\n",
       "  861,\n",
       "  862,\n",
       "  863,\n",
       "  864,\n",
       "  865,\n",
       "  866,\n",
       "  867,\n",
       "  868,\n",
       "  869,\n",
       "  870],\n",
       " 'university': [217,\n",
       "  218,\n",
       "  219,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  223,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239],\n",
       " 'hospital': [871,\n",
       "  872,\n",
       "  873,\n",
       "  874,\n",
       "  875,\n",
       "  876,\n",
       "  877,\n",
       "  878,\n",
       "  879,\n",
       "  880,\n",
       "  881,\n",
       "  882,\n",
       "  883,\n",
       "  884]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a7dad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iI_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43miI_c\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'iI_c' is not defined"
     ]
    }
   ],
   "source": [
    "len(iI_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeabfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "459\n",
      "173\n",
      "172\n",
      "23\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for c, idx_list in I_c.items():\n",
    "    print(len(idx_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24e4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xpress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
